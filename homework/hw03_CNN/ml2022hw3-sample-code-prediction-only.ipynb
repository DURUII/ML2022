{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a933595d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:54.133325Z",
     "iopub.status.busy": "2022-03-05T08:34:54.132652Z",
     "iopub.status.idle": "2022-03-05T08:34:58.119013Z",
     "shell.execute_reply": "2022-03-05T08:34:58.119993Z",
     "shell.execute_reply.started": "2022-03-02T11:34:09.005266Z"
    },
    "papermill": {
     "duration": 4.012064,
     "end_time": "2022-03-05T08:34:58.120311",
     "exception": false,
     "start_time": "2022-03-05T08:34:54.108247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        pass\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c2a50",
   "metadata": {
    "papermill": {
     "duration": 0.014686,
     "end_time": "2022-03-05T08:34:58.151688",
     "exception": false,
     "start_time": "2022-03-05T08:34:58.137002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This code is for generating predictions only\n",
    "\n",
    "## For this code to work as intended, please make sure the following:\n",
    "\n",
    "1. _exp_name is the same as your training code\n",
    "2. Classifier is the same as you training code\n",
    "3. Your trained model is save as a dataset and loaded with + Add data (See slides for detail)\n",
    "4. model.load_state_dict({path}) is the correct path to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e228b2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:58.184800Z",
     "iopub.status.busy": "2022-03-05T08:34:58.183797Z",
     "iopub.status.idle": "2022-03-05T08:34:58.187698Z",
     "shell.execute_reply": "2022-03-05T08:34:58.188259Z",
     "shell.execute_reply.started": "2022-03-02T11:34:16.230568Z"
    },
    "papermill": {
     "duration": 0.022184,
     "end_time": "2022-03-05T08:34:58.188430",
     "exception": false,
     "start_time": "2022-03-05T08:34:58.166246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_exp_name = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7e855f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:58.221913Z",
     "iopub.status.busy": "2022-03-05T08:34:58.220942Z",
     "iopub.status.idle": "2022-03-05T08:34:59.691340Z",
     "shell.execute_reply": "2022-03-05T08:34:59.690756Z",
     "shell.execute_reply.started": "2022-03-02T11:34:16.236989Z"
    },
    "papermill": {
     "duration": 1.488184,
     "end_time": "2022-03-05T08:34:59.691482",
     "exception": false,
     "start_time": "2022-03-05T08:34:58.203298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "now = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59500e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:59.728378Z",
     "iopub.status.busy": "2022-03-05T08:34:59.727211Z",
     "iopub.status.idle": "2022-03-05T08:34:59.735932Z",
     "shell.execute_reply": "2022-03-05T08:34:59.736480Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.814907Z"
    },
    "papermill": {
     "duration": 0.029172,
     "end_time": "2022-03-05T08:34:59.736718",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.707546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc06819b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:59.771259Z",
     "iopub.status.busy": "2022-03-05T08:34:59.770275Z",
     "iopub.status.idle": "2022-03-05T08:34:59.776038Z",
     "shell.execute_reply": "2022-03-05T08:34:59.776675Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.868774Z"
    },
    "papermill": {
     "duration": 0.024532,
     "end_time": "2022-03-05T08:34:59.776847",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.752315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    # You may add some transforms here.\n",
    "    # ToTensor() should be the last one of the transforms.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3db4ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:59.819877Z",
     "iopub.status.busy": "2022-03-05T08:34:59.818953Z",
     "iopub.status.idle": "2022-03-05T08:34:59.821923Z",
     "shell.execute_reply": "2022-03-05T08:34:59.821362Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.878025Z"
    },
    "papermill": {
     "duration": 0.030324,
     "end_time": "2022-03-05T08:34:59.822083",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.791759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,tfm=test_tfm,files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "        print(f\"One {path} sample\",self.files[0])\n",
    "        self.transform = tfm\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        #im = self.data[idx]\n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038c5545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:59.861222Z",
     "iopub.status.busy": "2022-03-05T08:34:59.860463Z",
     "iopub.status.idle": "2022-03-05T08:34:59.868503Z",
     "shell.execute_reply": "2022-03-05T08:34:59.867949Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.891852Z"
    },
    "papermill": {
     "duration": 0.031645,
     "end_time": "2022-03-05T08:34:59.868679",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.837034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f456a5a",
   "metadata": {
    "papermill": {
     "duration": 0.014586,
     "end_time": "2022-03-05T08:34:59.898700",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.884114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5385b443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:34:59.933830Z",
     "iopub.status.busy": "2022-03-05T08:34:59.933153Z",
     "iopub.status.idle": "2022-03-05T08:34:59.946791Z",
     "shell.execute_reply": "2022-03-05T08:34:59.947366Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.907523Z"
    },
    "papermill": {
     "duration": 0.034153,
     "end_time": "2022-03-05T08:34:59.947542",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.913389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One ../input/ml2022spring-hw3b/food11/test sample ../input/ml2022spring-hw3b/food11/test/0001.jpg\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "_dataset_dir = \"../input/ml2022spring-hw3b/food11\"\n",
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca008a",
   "metadata": {
    "papermill": {
     "duration": 0.01513,
     "end_time": "2022-03-05T08:34:59.978542",
     "exception": false,
     "start_time": "2022-03-05T08:34:59.963412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93fc35a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:35:00.012059Z",
     "iopub.status.busy": "2022-03-05T08:35:00.011372Z",
     "iopub.status.idle": "2022-03-05T08:35:00.299146Z",
     "shell.execute_reply": "2022-03-05T08:35:00.298464Z",
     "shell.execute_reply.started": "2022-03-02T11:34:17.931119Z"
    },
    "papermill": {
     "duration": 0.30585,
     "end_time": "2022-03-05T08:35:00.299435",
     "exception": true,
     "start_time": "2022-03-05T08:34:59.993585",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/sample_best.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2840425873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{_your_dataset_name}/{_exp_name}_best.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/sample_best.ckpt'"
     ]
    }
   ],
   "source": [
    "_your_dataset_name = \"\" \n",
    "if not len(_your_dataset_name):\n",
    "    print(_your_dataset_name)\n",
    "    assert (\"Default name detected, please fill in the name of your dataset(model checkpoint)\")\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_best = Classifier().to(device)\n",
    "model_best.load_state_dict(torch.load(f\"{_your_dataset_name}/{_exp_name}_best.ckpt\"))\n",
    "model_best.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cc795",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Predict\n",
    "\n",
    "#### Modify this part to do test time augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243bed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T11:34:21.51016Z",
     "iopub.status.busy": "2022-03-02T11:34:21.509663Z",
     "iopub.status.idle": "2022-03-02T11:35:02.155167Z",
     "shell.execute_reply": "2022-03-02T11:35:02.154431Z",
     "shell.execute_reply.started": "2022-03-02T11:34:21.510119Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052636d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T11:35:02.156813Z",
     "iopub.status.busy": "2022-03-02T11:35:02.156527Z",
     "iopub.status.idle": "2022-03-02T11:35:02.189302Z",
     "shell.execute_reply": "2022-03-02T11:35:02.18859Z",
     "shell.execute_reply.started": "2022-03-02T11:35:02.156775Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.354006,
   "end_time": "2022-03-05T08:35:01.127018",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-05T08:34:43.773012",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
